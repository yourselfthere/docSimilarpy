{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa76d8e-270f-4a2a-b436-0dc0d45a3fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "Test Image: invoice_77098.jpg\n",
      "Most Similar Image: invoice_77073.jpg\n",
      "Similarity Score: 0.9984165075420612\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "Test Image: invoice_102857.jpg\n",
      "Most Similar Image: invoice_102856.jpg\n",
      "Similarity Score: 0.9492247696676082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load pre-trained VGG16 model + higher level layers\n",
    "base_model = VGG16(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "def extract_image_features(img_path):\n",
    "    try:\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_data = image.img_to_array(img)\n",
    "        img_data = np.expand_dims(img_data, axis=0)\n",
    "        img_data = preprocess_input(img_data)\n",
    "        \n",
    "        features = model.predict(img_data)\n",
    "        return features.flatten()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features from {img_path}: {e}\")\n",
    "        return np.array([])\n",
    "\n",
    "def calculate_ssim(img_path1, img_path2):\n",
    "    try:\n",
    "        img1 = Image.open(img_path1).convert('L')  # Convert to grayscale\n",
    "        img2 = Image.open(img_path2).convert('L')  # Convert to grayscale\n",
    "        img1 = img1.resize((224, 224))\n",
    "        img2 = img2.resize((224, 224))\n",
    "        img1 = np.array(img1)\n",
    "        img2 = np.array(img2)\n",
    "        return ssim(img1, img2)\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating SSIM between {img_path1} and {img_path2}: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def calculate_combined_similarity(img_path1, img_path2, features1, features2, weight_ssim=0.5, weight_vgg16=0.5):\n",
    "    ssim_score = calculate_ssim(img_path1, img_path2)\n",
    "    vgg16_sim = np.dot(features1, features2) / (np.linalg.norm(features1) * np.linalg.norm(features2)) if features1.size and features2.size else 0.0\n",
    "    return weight_ssim * ssim_score + weight_vgg16 * vgg16_sim\n",
    "\n",
    "# Paths to training and test folders\n",
    "train_folder = \"./train\"\n",
    "test_folder = \"./test\"\n",
    "\n",
    "# List of training and test images\n",
    "train_images = [\"2024.03.15_0954.jpg\", \"2024.03.15_1145.jpg\", \"Faller_8.jpg\", \"invoice_77073.jpg\", \"invoice_102856.jpg\"]\n",
    "test_images = [\"invoice_77098.jpg\", \"invoice_102857.jpg\"]\n",
    "\n",
    "# Dictionary to store training image features\n",
    "database = {}\n",
    "\n",
    "# Extract and store features for training images\n",
    "for img_name in train_images:\n",
    "    img_path = os.path.join(train_folder, img_name)\n",
    "    features = extract_image_features(img_path)\n",
    "    database[img_name] = {\n",
    "        'path': img_path,\n",
    "        'features': features\n",
    "    }\n",
    "\n",
    "# Compare test images to training images\n",
    "for test_img in test_images:\n",
    "    test_img_path = os.path.join(test_folder, test_img)\n",
    "    test_features = extract_image_features(test_img_path)\n",
    "    \n",
    "    best_match = None\n",
    "    highest_similarity = 0\n",
    "    \n",
    "    for train_img, data in database.items():\n",
    "        similarity = calculate_combined_similarity(test_img_path, data['path'], test_features, data['features'])\n",
    "        if similarity > highest_similarity:\n",
    "            highest_similarity = similarity\n",
    "            best_match = train_img\n",
    "    \n",
    "    print(f\"Test Image: {test_img}\")\n",
    "    print(f\"Most Similar Image: {best_match}\")\n",
    "    print(f\"Similarity Score: {highest_similarity}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e76fa-9d50-4a70-9aa9-d402ec5e92fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (invoice_similarity)",
   "language": "python",
   "name": "invoice_similarity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
